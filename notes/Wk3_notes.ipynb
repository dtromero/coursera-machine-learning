{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Machine Learning Wk 3\n",
    "\n",
    "<h3 align=\"right\"><u>Video: Classification Problems</u></h3>\n",
    "Examples\n",
    "* Email: Spam/Not Spam?\n",
    "* Online Transactions: Fraudulent (Yes/No)?\n",
    "* Tumor: Malignant/Benign?\n",
    "\n",
    "$y \\in \\{0, 1\\}$\n",
    "* 0: \"Negative Class\" (e.g. benign tumor)\n",
    "* 1: \"Positive Class\" (e.g. malignant tumor)\n",
    "\n",
    "By convention, 0 indicates an absence of something. But the assignment is somewhat arbitrary.\n",
    "#####Applying linear regression to a classification problem\n",
    "<img src=\"images/wk3_classification_529.png\">\n",
    "\n",
    "Threshold classifier output $h_\\theta(x)$ at 0.5:\n",
    "- If $h_\\theta(x) >= 0.5$, predict \"y=1\"\n",
    "- If $h_\\theta(x) < 0.5$, predict \"y=0\"\n",
    "\n",
    "By adding one outlier, linear regression no longer gives us a good model (<span style=\"color:magenta\">magenta</span> line vs. <span style=\"color:blue\">blue</span> line). For this reason, <b>it is not a good idea to use linear regression for classification problems.</b>\n",
    "\n",
    "* <b>Linear regression</b>: $h_\\theta(x)$ can be $>1$ or $<0$\n",
    "\n",
    "* <b>Logistic regression</b>: $0 <= h_\\theta(x) <= 1$ ~ has the property that the output of logistic regression always has values between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"right\"><u>Video: Hypothesis Representation</u></h3>\n",
    "\n",
    "Determine the function we will use to represent the hypothesis for classification problems.\n",
    "#####Logistic Regression Model\n",
    "<img src=\"images/wk3_hypothesis_305.png\" align=\"right\" width=\"50%\">\n",
    "Want $0 <= h_\\theta(x) <= 1$\n",
    "\n",
    "$\\qquad h_\\theta(x) = g(\\theta^Tx)$\n",
    "\n",
    "$\\qquad g(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "$\\qquad h_\\theta(x) = \\frac{1}{1+e^{-\\theta^Tx}}$\n",
    "\n",
    "\n",
    "Plotted to the right:\n",
    "* <b>Sigmoid function</b><br>\n",
    "* <b>Logistic function</b><br> Two terms are interchangeable and can be used to refer to the function g(z).\n",
    "\n",
    "<b>Interpretation of Hypothesis Output</b><br>\n",
    "$h_\\theta(x) =$ estimated probability that $y = 1$ on input x\n",
    "\n",
    "Example: $If x = \\begin{bmatrix} x_0 \\\\ x_1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ tumorSize \\end{bmatrix}$<br>\n",
    "$\\qquad h_\\theta(x) = 0.7$<br><br>\n",
    "Tell patient that 70% chance of tumor being malignant.\n",
    "\n",
    "$h_\\theta(x) = p(y=1 | x;0)$<br>\n",
    "\"probability that y=1, given x, parameterized by $\\theta$\"\n",
    "<br><br>\n",
    "\n",
    "<img src=\"images/wk3_hypothesis_314.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"right\"><u>Video: Decision Boundary</u></h3>\n",
    "\n",
    "Supose predict:\n",
    "<img src=\"images/wk3_decision_405.png\" align=\"right\" width=\"50%\">\n",
    "* <span style=\"color:magenta\">\"$y = 1$\" if $h_\\theta(x) >= 0.5$ <br>\n",
    "$\\qquad g(z) >= 0.5$ when $z >= 0$ <br>\n",
    "$\\qquad h_\\theta(x) = g(\\theta^Tx) >= 0.5$ <br>\n",
    "$\\qquad whenever\\;\\theta^Tx >= 0$</span>\n",
    "\n",
    "\n",
    "* <span style=\"color:red\">\"$y = 0$\" if $h_\\theta(x) < 0.5$ <br>\n",
    "$\\qquad g(z) < 0.5$ when $z < 0$ <br>\n",
    "$\\qquad h_\\theta(x) = g(\\theta^Tx) < 0.5$ <br>\n",
    "$\\qquad whenever\\;\\theta^Tx < 0$</span>\n",
    "<br><br><br>\n",
    "\n",
    "<b>Decision Boundary Example</b>\n",
    "<img src=\"images/wk3_decision_813.png\" align=\"right\" width=\"40%\">\n",
    "\n",
    "$h_\\theta(x) = g(\\theta_0 + \\theta_1x_1 + \\theta_2x_2)$<br>\n",
    "parameters fit (next video): $\\theta = \\begin{bmatrix} -3 \\\\ 1 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "Predict \"y = 1\" if $-3 +x_1 + x_2 >= 0$<br>\n",
    "$\\qquad -3 + x_1 + x_2 == \\theta^Tx$<br>\n",
    "<span style=\"color:magenta\">$\\qquad x_1 + x_2 = 3$</span>\n",
    "\n",
    "<span style=\"color:magenta\">Magenta line is Decision Boundary</span>\n",
    "<br><br><br>\n",
    "\n",
    "<b>Non-linear decision boundaries</b>\n",
    "<img src=\"images/wk3_decision_1230.png\" align=\"right\" width=\"40%\">\n",
    "\n",
    "$h_\\theta(x) = g(\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_1^2 + \\theta_2^2)$\n",
    "\n",
    "$\\theta = \\begin{bmatrix} -1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "Predict \"y=1\" if $-1 + x_1^2 + x_2^2 >= 0$<br>\n",
    "<span style=\"color:magenta\">$\\qquad x_1^2 + x_2^2 >= 1$</span>\n",
    "\n",
    "\n",
    "Higher order poloynomials can give even more complex decision boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"right\"><u>Video: Cost Function</u></h3>\n",
    "\n",
    "How to fit parameters $\\theta$ for logistic regression.\n",
    "\n",
    "<b>Supervised learning model of fitting a logistic regression model</b>\n",
    "\n",
    "Training set: $\\{(x^1,y^1),(x^2,y^2),\\cdots,(x^m,y^m)\\}$\n",
    "\n",
    "m examples $\\qquad x \\in \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\cdots \\\\ x_n \\end{bmatrix}$ \n",
    "$\\qquad x_0 = 1, y \\in \\{0,1\\}$\n",
    "\n",
    "\n",
    "$h_\\theta(x) = \\frac{1}{1+e^{-\\theta^Tx}}$\n",
    "\n",
    "<b>How to choose parameters $\\theta$?</b>\n",
    "\n",
    "####Cost Function\n",
    "Linear regression: $J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\frac{1}{2} (h_\\theta(x^i) - y^i)^2 $\n",
    "\n",
    "This cost function is non-convex when applied to logistic regression.\n",
    "\n",
    "<img src=\"images/wk3_cost_420.png\" width=\"90%\">\n",
    "\n",
    "\n",
    "####Logistic cost function\n",
    "<img src=\"images/wk3_cost_609.png\" align=\"right\" width=\"40%\">\n",
    "$Cost(h_\\theta(x),y) = \\begin{cases} \n",
    "-log(h_\\theta(x)) & \\text{if y = 1}\\\\\n",
    "-log(1-h\\theta(x)) & \\text{if y = 0}\n",
    "\\end{cases}$\n",
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "<img src=\"images/wk3_cost_620.png\" align=\"left\" width=\"30%\">\n",
    "Cost = 0 if y =1, $h_\\theta(x)$ = 1<br>\n",
    "But as $h_\\theta(x) \\to 0 \\\\ Cost \\to \\infty$\n",
    "\n",
    "Captures intuition that if $h_\\theta(x) = 0$, (predict P(y =1 | 0;$\\theta$) = 0), but y =1, we'll penalize learning algorith by a very large cost\n",
    "\n",
    "<img src=\"images/wk3_cost_1000.png\" align=\"right\" width=\"30%\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"right\"><u>Video: Simplified Cost Function and Gradient Descent</u></h3>\n",
    "\n",
    "####Logistic regression cost function\n",
    "$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m Cost(h_\\theta(x^{(i)}),y^{(i)})\\\\\n",
    "Cost(h_\\theta(x),(y)) = \\begin{cases}\n",
    "-log(h_\\theta(x)) & \\text{if y = 1}\\\\\n",
    "-log(1-h\\theta(x)) & \\text{if y = le0}\n",
    "\\end{cases}$<br>\n",
    "Note: y=0 or 1 always\n",
    "<br><br>\n",
    "Simplfied way of writing the cost function:<br>\n",
    "$\\begin{align}\n",
    "Cost(h_\\theta(x),(y)) &= -ylog(h_\\theta(x)) - (1-y)log(1-h_\\theta(x))\\\\\n",
    "\\text{If y=1} &= -log(h_\\theta(x))\\\\\n",
    "\\text{If y=0} &= -log(1-h_\\theta(x))\n",
    "\\end{align}$\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "$$(\\theta) = - \\frac{1}{m} [\\sum_{i=1}^m y^{(i)} log\\,h_\\theta(x^{(i)}) + (1-y^{(i)})log(1-h_\\theta(x^{(i)})) ]$$\n",
    "</span>\n",
    "$$\\text{To fit parameters} \\theta:\\\\\n",
    "min_\\theta J(\\theta)\\\\\n",
    "\\text{To make a prediction given new x:}\\\\\n",
    "\\text{Output } h_\\theta=\\frac{1}{1+e^{-\\theta^Tx}}$$\n",
    "\n",
    "<img src=\"images/wk3_gradient_830.png\" width=\"90%\">\n",
    "\n",
    "Vectorized implementation:<br>\n",
    "$$\\theta := \\theta - \\alpha \\frac{1}{m} \\sum_{i=1}^m [(h_\\theta(x^i)-y^i) * x^i]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"right\"><u>Video: Advanced Optimization</u></h3>\n",
    "\n",
    "Gradient descent is one example of an algorithm that can be used, but there are other algos that may be more efficient:\n",
    "* Conjugate gradient\n",
    "* BFGS\n",
    "* L-BFGS\n",
    "\n",
    "Advantages: No need to manually pick $\\alpha$, often faster than gradient descent<br>\n",
    "Disadvantages: More complex\n",
    "\n",
    "<img src=\"images/wk3_adv_824.png\" width=\"90%\">\n",
    "\n",
    "<img src=\"images/wk3_adv_1314.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"right\"><u>Video: Multiclass Classification: One-vs-all</u></h3>\n",
    "\n",
    "Examples:\n",
    "* Email foldering/tagging: Work, Friends, Family, Hobby (four classes: y=1/2/3/4)\n",
    "* Medical diagrams: Not ill, Cold, Flu (y=1/2/3)\n",
    "* Weather: Sunny, Cloudy, Rain Snow (y=1/2/3)\n",
    "Gradient descent is one example of an algorithm that can be used, but there are other algos that may be more efficient:\n",
    "\n",
    "\n",
    "<img src=\"images/wk3_multi_430.png\" width=\"90%\">\n",
    "\n",
    "Split up the classification problem into many one-vs-all problems.\n",
    "\n",
    "Train a logistic regression classifier $h_\\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y = i$.\n",
    "\n",
    "On a new input $x$, to make a prediction, pick the class $i$ that maximizes:<br>\n",
    "$max_i\\,h_\\theta^{(i)}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
